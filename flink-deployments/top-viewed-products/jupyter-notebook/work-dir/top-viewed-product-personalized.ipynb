{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471f257e-a83f-4cf0-b734-8fa9a9189f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.1)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.24.1 tenacity-9.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878768b6-7f52-400f-8837-5e338e9fd634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "  Downloading pillow-11.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.54.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.24.3)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.1)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/home/NBuser/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2914e13f-a85d-4def-b709-9b7bb2a14579",
   "metadata": {},
   "source": [
    "## Record Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89521062-3a35-4686-ad43-55c34d9dc591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 13:21:53 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records in Delta table 1204\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/top-product-views-users-hourly\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    \n",
    "    print(f\"# of records in Delta table {df.count()}\")\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd61378-9008-4dbe-8e7a-9a6067511a43",
   "metadata": {},
   "source": [
    "## View All Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae20336b-0c87-4fc4-884e-2d16b0439a90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-------+----------+--------------------+--------------------+\n",
      "|          product_id|        product_name|               brand|             user_id|         user_name|               state|country|view_count|           starttime|             endtime|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-------+----------+--------------------+--------------------+\n",
      "|fa7d3924-645e-47c...|    Perf Impreza 599|Oberbrunner, Diet...|621e8f16-703c-4a3...|Beauregard Garahan|District of Columbia|     US|       113|2024-10-24 18:45:...|2024-10-24 19:45:...|\n",
      "|fa7d3924-645e-47c...|    Perf Impreza 599|Oberbrunner, Diet...|621e8f16-703c-4a3...|Beauregard Garahan|District of Columbia|     US|       113|2024-10-24 19:00:...|2024-10-24 20:00:...|\n",
      "|fa7d3924-645e-47c...|    Perf Impreza 599|Oberbrunner, Diet...|621e8f16-703c-4a3...|Beauregard Garahan|District of Columbia|     US|       113|2024-10-24 19:15:...|2024-10-24 20:15:...|\n",
      "|fa7d3924-645e-47c...|    Perf Impreza 599|Oberbrunner, Diet...|621e8f16-703c-4a3...|Beauregard Garahan|District of Columbia|     US|       113|2024-10-24 19:30:...|2024-10-24 20:30:...|\n",
      "|5784dda3-4e6d-42c...|Sidekick TrailRun...|Beer, DAmore and ...|18dfc888-ad29-45f...|   Elmer Trethowan|      North Carolina|     US|       113|2024-10-24 18:45:...|2024-10-24 19:45:...|\n",
      "|5784dda3-4e6d-42c...|Sidekick TrailRun...|Beer, DAmore and ...|18dfc888-ad29-45f...|   Elmer Trethowan|      North Carolina|     US|       113|2024-10-24 19:00:...|2024-10-24 20:00:...|\n",
      "|5784dda3-4e6d-42c...|Sidekick TrailRun...|Beer, DAmore and ...|18dfc888-ad29-45f...|   Elmer Trethowan|      North Carolina|     US|       113|2024-10-24 19:15:...|2024-10-24 20:15:...|\n",
      "|5784dda3-4e6d-42c...|Sidekick TrailRun...|Beer, DAmore and ...|18dfc888-ad29-45f...|   Elmer Trethowan|      North Carolina|     US|       113|2024-10-24 19:30:...|2024-10-24 20:30:...|\n",
      "|3f8fec3c-007a-462...|Sidekick Spectra5...|Oberbrunner, Diet...|d44fa65e-b6a1-414...|    Carver Lithgow|       West Virginia|     US|       115|2024-10-24 18:45:...|2024-10-24 19:45:...|\n",
      "|3f8fec3c-007a-462...|Sidekick Spectra5...|Oberbrunner, Diet...|d44fa65e-b6a1-414...|    Carver Lithgow|       West Virginia|     US|       115|2024-10-24 19:00:...|2024-10-24 20:00:...|\n",
      "|3f8fec3c-007a-462...|Sidekick Spectra5...|Oberbrunner, Diet...|d44fa65e-b6a1-414...|    Carver Lithgow|       West Virginia|     US|       115|2024-10-24 19:15:...|2024-10-24 20:15:...|\n",
      "|3f8fec3c-007a-462...|Sidekick Spectra5...|Oberbrunner, Diet...|d44fa65e-b6a1-414...|    Carver Lithgow|       West Virginia|     US|       115|2024-10-24 19:30:...|2024-10-24 20:30:...|\n",
      "|248d5e0c-288b-405...|TrailRunner Impre...|Okuneva, McCullou...|f03097f9-0d61-4c3...|      Janka Looker|        Pennsylvania|     US|       119|2024-10-24 18:45:...|2024-10-24 19:45:...|\n",
      "|248d5e0c-288b-405...|TrailRunner Impre...|Okuneva, McCullou...|f03097f9-0d61-4c3...|      Janka Looker|        Pennsylvania|     US|       119|2024-10-24 19:00:...|2024-10-24 20:00:...|\n",
      "|248d5e0c-288b-405...|TrailRunner Impre...|Okuneva, McCullou...|f03097f9-0d61-4c3...|      Janka Looker|        Pennsylvania|     US|       119|2024-10-24 19:15:...|2024-10-24 20:15:...|\n",
      "|248d5e0c-288b-405...|TrailRunner Impre...|Okuneva, McCullou...|f03097f9-0d61-4c3...|      Janka Looker|        Pennsylvania|     US|       119|2024-10-24 19:30:...|2024-10-24 20:30:...|\n",
      "|6b1f5211-d8e9-404...|Sidekick Impreza 663|Macejkovic, Walte...|05fda03e-611d-442...| Allianora Reymers|          California|     US|       116|2024-10-24 18:45:...|2024-10-24 19:45:...|\n",
      "|6b1f5211-d8e9-404...|Sidekick Impreza 663|Macejkovic, Walte...|05fda03e-611d-442...| Allianora Reymers|          California|     US|       116|2024-10-24 19:00:...|2024-10-24 20:00:...|\n",
      "|6b1f5211-d8e9-404...|Sidekick Impreza 663|Macejkovic, Walte...|05fda03e-611d-442...| Allianora Reymers|          California|     US|       116|2024-10-24 19:15:...|2024-10-24 20:15:...|\n",
      "|6b1f5211-d8e9-404...|Sidekick Impreza 663|Macejkovic, Walte...|05fda03e-611d-442...| Allianora Reymers|          California|     US|       116|2024-10-24 19:30:...|2024-10-24 20:30:...|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "# of records in Delta table None\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/top-product-views-users-hourly\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    # Convert total_sale_price to a standard numeric format\n",
    "    #df = df.withColumn(\"total_sale_pice\", col(\"total_sale_pice\").cast(\"decimal(20, 8)\"))\n",
    "\n",
    "    print(f\"# of records in Delta table {df.show(truncate=True)}\")\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f76732-1986-41e4-a2bd-c3b29b5ba881",
   "metadata": {},
   "source": [
    "## View products most viewed during the latest past hour by every customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc9b59d8-b067-4705-b9d0-2f99618e8759",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-----------+---------+--------------------+-------------------+\n",
      "|           productId|         productName|        productBrand|              userId|           userName|           userState|userCountry|viewCount|          start_time|           end_time|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-----------+---------+--------------------+-------------------+\n",
      "|fa7d3924-645e-47c...|    Perf Impreza 599|Oberbrunner, Diet...|621e8f16-703c-4a3...| Beauregard Garahan|District of Columbia|         US|      113|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|5784dda3-4e6d-42c...|Sidekick TrailRun...|Beer, DAmore and ...|18dfc888-ad29-45f...|    Elmer Trethowan|      North Carolina|         US|      113|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|3f8fec3c-007a-462...|Sidekick Spectra5...|Oberbrunner, Diet...|d44fa65e-b6a1-414...|     Carver Lithgow|       West Virginia|         US|      115|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|248d5e0c-288b-405...|TrailRunner Impre...|Okuneva, McCullou...|f03097f9-0d61-4c3...|       Janka Looker|        Pennsylvania|         US|      119|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|6b1f5211-d8e9-404...|Sidekick Impreza 663|Macejkovic, Walte...|05fda03e-611d-442...|  Allianora Reymers|          California|         US|      116|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|9b1f3411-c7a5-414...|Sidekick Impreza 630|Oberbrunner, Diet...|6669d0f3-a620-4f3...|   Shoshana Kurdani|          California|         US|      104|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|1edce639-9f89-483...| TrailRunner Max 160|Tillman, Effertz ...|01ebb27a-91b6-400...|     Kerby Crocumbe|      North Carolina|         US|      113|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|f7554f88-c110-498...| Pro TrailRunner 961|Tillman, Effertz ...|0b5b416f-ef37-4e5...|  Dylan McGerraghty|         Connecticut|         US|      117|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|a4c6441d-0bdc-4c9...|TrailRunner Impre...|Tillman, Effertz ...|a21d0cbd-0934-444...|    Corena McCurley|           Louisiana|         US|      118|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|d993a27e-3267-4e8...|Sidekick TrailRun...|Okuneva, McCullou...|bd014615-5901-45e...|       Berkie Liley|            Oklahoma|         US|      119|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|ec756e23-e52b-4b0...|TrailRunner Impre...|Macejkovic, Walte...|2b601c0c-7edc-49d...|      Tamar Naisbet|           Tennessee|         US|      105|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|f2facb36-5ee3-4f6...|Spectra5 TrailRun...|Lebsack, Wiza and...|1639d91f-fe80-4c0...| Ariella Espinheira|              Nevada|         US|       98|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|2ae26388-fc97-417...|TrailRunner Impre...|Okuneva, McCullou...|90cf118c-2ba5-437...|      Ossie Duckitt|             Alabama|         US|      103|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|e7374b69-0a88-408...|TrailRunner Impre...|Oberbrunner, Diet...|96cf6a58-b771-4d5...|       Gilda Pagnin|            Illinois|         US|       88|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|89b9c81d-3c80-4a1...| TrailRunner Max 366|Tillman, Effertz ...|ddbf0216-8700-4c1...|     Morlee Zwicker|       West Virginia|         US|      108|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|fb3f2877-c85d-41b...|Sidekick TrailRun...|Macejkovic, Walte...|cdaa75a3-3c2b-470...|       Jeno Blakely|            Virginia|         US|      110|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|6505f118-828a-45b...| Pro TrailRunner 985|Tillman, Effertz ...|defb3345-f536-406...| Orlando Leighfield|            New York|         US|      117|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|1edce639-9f89-483...| TrailRunner Max 160|Tillman, Effertz ...|b1cf713e-ada0-434...|Augustine Daveridge|             Florida|         US|       94|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|5784dda3-4e6d-42c...|Sidekick TrailRun...|Beer, DAmore and ...|66d3668a-26bc-4d7...|    Bellanca Capnor|            Nebraska|         US|      119|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "|f2facb36-5ee3-4f6...|Spectra5 TrailRun...|Lebsack, Wiza and...|26bcb953-3522-43a...|    Neel Strangeway|             Florida|         US|      112|2024-10-24 19:30:...|2024-10-24 20:30:00|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-----------+---------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "# of records in Delta table None\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/top-product-views-users-hourly\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    # Convert total_sale_price to a standard numeric format\n",
    "    #df = df.withColumn(\"total_sale_pice\", col(\"total_sale_pice\").cast(\"decimal(20, 8)\"))\n",
    "    \n",
    "    # Get the latest time window for each user based on the endtime\n",
    "    latest_df = df.withColumn(\"endtime\", col(\"endtime\").cast(\"timestamp\"))\\\n",
    "        .groupBy(\"user_id\", \"user_name\")\\\n",
    "        .agg(F.max(\"endtime\").alias(\"latest_endtime\"))\n",
    "    \n",
    "    df_renamed = df.select(\n",
    "        col(\"product_id\").alias(\"productId\"),\n",
    "        col(\"product_name\").alias(\"productName\"),\n",
    "        col(\"brand\").alias(\"productBrand\"),\n",
    "        col(\"user_id\").alias(\"userId\"),\n",
    "        col(\"user_name\").alias(\"userName\"),\n",
    "        col(\"state\").alias(\"userState\"),\n",
    "        col(\"country\").alias(\"userCountry\"),\n",
    "        col(\"view_count\").alias(\"viewCount\"),\n",
    "        col(\"starttime\").alias(\"start_time\"),\n",
    "        col(\"endtime\").cast(\"timestamp\").alias(\"end_time\")\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Join back with the original DataFrame to get the other columns for the latest window\n",
    "    latest_records_df = latest_df.join(df_renamed, (df_renamed.userId == latest_df.user_id) & (df_renamed.end_time == latest_df.latest_endtime))\\\n",
    "        .select(\"productId\", \"productName\", \"productBrand\", \"userId\", \"userName\", \"userState\", \"userCountry\", \"viewCount\", \"start_time\", \"end_time\")\n",
    "\n",
    "    print(f\"# of records in Delta table {latest_records_df.show(truncate=True)}\")\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3591ac-d170-4678-941a-0fc8f0e21f2b",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85865700-d09c-49f2-bab7-4547edcce6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_28.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import max \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\"\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/top-product-views-users-hourly\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    \n",
    "    # Get the latest time window for each user based on the endtime\n",
    "    latest_df = df.withColumn(\"endtime\", col(\"endtime\").cast(\"timestamp\"))\\\n",
    "        .groupBy(\"user_id\", \"user_name\")\\\n",
    "        .agg(F.max(\"endtime\").alias(\"latest_endtime\"))\n",
    "    \n",
    "    df_renamed = df.select(\n",
    "        col(\"product_id\").alias(\"productId\"),\n",
    "        col(\"product_name\").alias(\"productName\"),\n",
    "        col(\"brand\").alias(\"productBrand\"),\n",
    "        col(\"user_id\").alias(\"userId\"),\n",
    "        col(\"user_name\").alias(\"userName\"),\n",
    "        col(\"state\").alias(\"userState\"),\n",
    "        col(\"country\").alias(\"userCountry\"),\n",
    "        col(\"view_count\").alias(\"viewCount\"),\n",
    "        col(\"starttime\").alias(\"start_time\"),\n",
    "        col(\"endtime\").cast(\"timestamp\").alias(\"end_time\")\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Join back with the original DataFrame to get the other columns for the latest window\n",
    "    latest_records_df = latest_df.join(df_renamed, (df_renamed.userId == latest_df.user_id) & (df_renamed.end_time == latest_df.latest_endtime))\\\n",
    "        .select(\"productId\", \"productName\", \"productBrand\", \"userId\", \"userName\", \"userState\", \"userCountry\", \"viewCount\", \"start_time\", \"end_time\")\n",
    "    \n",
    "    latest_records_df_pd = latest_records_df.toPandas()\n",
    "    \n",
    "    # Combine product and time window details for labels\n",
    "    latest_records_df_pd['ProductDetails'] = latest_records_df_pd['productBrand'] + \" - \" + latest_records_df_pd['productName'] + \"<br>View Count: \" + latest_records_df_pd['viewCount'].astype(str)\n",
    "    latest_records_df_pd['TimeWindow'] = latest_records_df_pd['start_time'] + \" to \" + latest_records_df_pd['end_time'].astype(str)\n",
    "    \n",
    "    # Plotly interactive bar chart\n",
    "    fig = px.bar(\n",
    "        latest_records_df_pd,\n",
    "        x=\"viewCount\",\n",
    "        y=\"userName\",\n",
    "        color=\"productBrand\",\n",
    "        text=\"ProductDetails\",\n",
    "        hover_data={\"TimeWindow\": True},\n",
    "        orientation=\"h\",\n",
    "        title=\"Most Viewed Products by Each Customer in the last hour\"\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"View Count\",\n",
    "        yaxis_title=\"Customer\",\n",
    "        legend_title=\"Product Brand\"\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ab748-fa72-409b-9c2d-e25420d73bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
