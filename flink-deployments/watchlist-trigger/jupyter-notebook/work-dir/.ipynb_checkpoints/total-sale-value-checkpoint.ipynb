{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471f257e-a83f-4cf0-b734-8fa9a9189f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.1)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.24.1 tenacity-9.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878768b6-7f52-400f-8837-5e338e9fd634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "  Downloading pillow-11.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.54.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.24.3)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.1)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/home/NBuser/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2914e13f-a85d-4def-b709-9b7bb2a14579",
   "metadata": {},
   "source": [
    "## Record Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89521062-3a35-4686-ad43-55c34d9dc591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 02:14:45 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records in Delta table 13\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/avg-sale-value-hourly\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    \n",
    "    print(f\"# of records in Delta table {df.count()}\")\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd61378-9008-4dbe-8e7a-9a6067511a43",
   "metadata": {},
   "source": [
    "## View Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae20336b-0c87-4fc4-884e-2d16b0439a90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------+---------------------+\n",
      "|total_sale_pice   |starttime            |endtime              |\n",
      "+------------------+---------------------+---------------------+\n",
      "|112633496.00000000|2024-10-24 18:45:00.0|2024-10-24 19:45:00.0|\n",
      "|112633496.00000000|2024-10-24 19:00:00.0|2024-10-24 20:00:00.0|\n",
      "|112633496.00000000|2024-10-24 19:15:00.0|2024-10-24 20:15:00.0|\n",
      "|112633496.00000000|2024-10-24 19:30:00.0|2024-10-24 20:30:00.0|\n",
      "|57625972.00000000 |2024-10-29 21:30:00.0|2024-10-29 22:30:00.0|\n",
      "|57885952.00000000 |2024-10-29 21:45:00.0|2024-10-29 22:45:00.0|\n",
      "|57885952.00000000 |2024-10-29 22:00:00.0|2024-10-29 23:00:00.0|\n",
      "|57885952.00000000 |2024-10-29 22:15:00.0|2024-10-29 23:15:00.0|\n",
      "|259980.00000000   |2024-10-29 22:30:00.0|2024-10-29 23:30:00.0|\n",
      "|182767576.00000000|2024-10-30 01:15:00.0|2024-10-30 02:15:00.0|\n",
      "|182767576.00000000|2024-10-30 01:30:00.0|2024-10-30 02:30:00.0|\n",
      "|182767576.00000000|2024-10-30 01:45:00.0|2024-10-30 02:45:00.0|\n",
      "|182767576.00000000|2024-10-30 02:00:00.0|2024-10-30 03:00:00.0|\n",
      "+------------------+---------------------+---------------------+\n",
      "\n",
      "# of records in Delta table None\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/avg-sale-value-hourly\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    # Convert total_sale_price to a standard numeric format\n",
    "    df = df.withColumn(\"total_sale_pice\", col(\"total_sale_pice\").cast(\"decimal(20, 8)\"))\n",
    "\n",
    "    print(f\"# of records in Delta table {df.show(truncate=False)}\")\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3591ac-d170-4678-941a-0fc8f0e21f2b",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85865700-d09c-49f2-bab7-4547edcce6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_6.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import max \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\"\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/avg-sale-value-hourly\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    \n",
    "    latest_df_pd = df.toPandas()\n",
    "    \n",
    "    # Convert time columns to datetime format\n",
    "    latest_df_pd['starttime'] = pd.to_datetime(latest_df_pd['starttime'])\n",
    "    latest_df_pd['endtime'] = pd.to_datetime(latest_df_pd['endtime'])\n",
    "    \n",
    "    # Create a new column for color based on day of the week\n",
    "    latest_df_pd['time_period'] = latest_df_pd['endtime'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    fig = px.bar(latest_df_pd, x='starttime', y='total_sale_pice', \n",
    "             title=\"Total Sales per Time Window\",\n",
    "             color=\"time_period\",\n",
    "             labels={'starttime': 'Time Window Start', 'endtime': 'Time Window End', 'total_sale_pice': 'Total Sale Price (Millions)'},\n",
    "             text='total_sale_pice')\n",
    "\n",
    "    # Add labels to each bar for better clarity\n",
    "    fig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\n",
    "\n",
    "    # Customize layout for readability\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Start Time of Time Window\",\n",
    "        yaxis_title=\"Total Sale Price (Millions)\",\n",
    "        xaxis_tickformat='%Y-%m-%d %H:%M',\n",
    "        xaxis_rangeslider_visible=True,\n",
    "        yaxis_type=\"log\"  # Apply logarithmic scale to y-axis\n",
    "\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ab748-fa72-409b-9c2d-e25420d73bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
