{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471f257e-a83f-4cf0-b734-8fa9a9189f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.1)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.24.1 tenacity-9.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878768b6-7f52-400f-8837-5e338e9fd634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "  Downloading pillow-11.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.54.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.24.3)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.1)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/home/NBuser/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2914e13f-a85d-4def-b709-9b7bb2a14579",
   "metadata": {},
   "source": [
    "## Record Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89521062-3a35-4686-ad43-55c34d9dc591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:===========>                                            (4 + 16) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records in Delta table 1460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/order-count-daily\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    \n",
    "    print(f\"# of records in Delta table {df.count()}\")\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd61378-9008-4dbe-8e7a-9a6067511a43",
   "metadata": {},
   "source": [
    "## View Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae20336b-0c87-4fc4-884e-2d16b0439a90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------+--------------------------------+------------------------+-------------------+-------------------+\n",
      "|product_id                          |order_count|brand                           |name                    |starttime          |endtime            |\n",
      "+------------------------------------+-----------+--------------------------------+------------------------+-------------------+-------------------+\n",
      "|d993a27e-3267-4e81-9937-903f8b7dedfd|3          |Okuneva, McCullough and Reynolds|Sidekick TrailRunner 454|2024-10-24 00:00:00|2024-10-25 00:00:00|\n",
      "|d993a27e-3267-4e81-9937-903f8b7dedfd|2          |Okuneva, McCullough and Reynolds|Sidekick TrailRunner 454|2024-10-29 00:00:00|2024-10-30 00:00:00|\n",
      "|d993a27e-3267-4e81-9937-903f8b7dedfd|2          |Okuneva, McCullough and Reynolds|Sidekick TrailRunner 454|2024-10-30 00:00:00|2024-10-31 00:00:00|\n",
      "|fb3f2877-c85d-41b6-ae74-9d05b3eba1b5|1          |Macejkovic, Walter and Cummings |Sidekick TrailRunner 881|2024-10-24 00:00:00|2024-10-25 00:00:00|\n",
      "|fb3f2877-c85d-41b6-ae74-9d05b3eba1b5|1          |Macejkovic, Walter and Cummings |Sidekick TrailRunner 881|2024-10-29 00:00:00|2024-10-30 00:00:00|\n",
      "|fb3f2877-c85d-41b6-ae74-9d05b3eba1b5|2          |Macejkovic, Walter and Cummings |Sidekick TrailRunner 881|2024-10-30 00:00:00|2024-10-31 00:00:00|\n",
      "|17215155-d06a-4f76-9e9a-89e42a327c40|1          |Okuneva, McCullough and Reynolds|Impreza TrailRunner 252 |2024-10-24 00:00:00|2024-10-25 00:00:00|\n",
      "|17215155-d06a-4f76-9e9a-89e42a327c40|1          |Okuneva, McCullough and Reynolds|Impreza TrailRunner 252 |2024-10-29 00:00:00|2024-10-30 00:00:00|\n",
      "|17215155-d06a-4f76-9e9a-89e42a327c40|3          |Okuneva, McCullough and Reynolds|Impreza TrailRunner 252 |2024-10-30 00:00:00|2024-10-31 00:00:00|\n",
      "|e7374b69-0a88-408b-b788-1160366b0b8b|2          |Oberbrunner, Dietrich and Hickle|TrailRunner Impreza 710 |2024-10-24 00:00:00|2024-10-25 00:00:00|\n",
      "|e7374b69-0a88-408b-b788-1160366b0b8b|3          |Oberbrunner, Dietrich and Hickle|TrailRunner Impreza 710 |2024-10-29 00:00:00|2024-10-30 00:00:00|\n",
      "|e7374b69-0a88-408b-b788-1160366b0b8b|2          |Oberbrunner, Dietrich and Hickle|TrailRunner Impreza 710 |2024-10-30 00:00:00|2024-10-31 00:00:00|\n",
      "|2ae26388-fc97-4170-a3a4-c8b02b31a803|3          |Okuneva, McCullough and Reynolds|TrailRunner Impreza 984 |2024-10-24 00:00:00|2024-10-25 00:00:00|\n",
      "|2ae26388-fc97-4170-a3a4-c8b02b31a803|1          |Okuneva, McCullough and Reynolds|TrailRunner Impreza 984 |2024-10-29 00:00:00|2024-10-30 00:00:00|\n",
      "|2ae26388-fc97-4170-a3a4-c8b02b31a803|1          |Okuneva, McCullough and Reynolds|TrailRunner Impreza 984 |2024-10-30 00:00:00|2024-10-31 00:00:00|\n",
      "|8ba6a0a4-b76c-40e6-ba4b-cd34c3db931f|1          |Oberbrunner, Dietrich and Hickle|Sidekick Spectra5 171   |2024-10-24 00:00:00|2024-10-25 00:00:00|\n",
      "|8ba6a0a4-b76c-40e6-ba4b-cd34c3db931f|1          |Oberbrunner, Dietrich and Hickle|Sidekick Spectra5 171   |2024-10-29 00:00:00|2024-10-30 00:00:00|\n",
      "|8ba6a0a4-b76c-40e6-ba4b-cd34c3db931f|2          |Oberbrunner, Dietrich and Hickle|Sidekick Spectra5 171   |2024-10-30 00:00:00|2024-10-31 00:00:00|\n",
      "|eef5227c-fadf-46e1-a8f1-be969e48965d|1          |Macejkovic, Walter and Cummings |TrailRunner Impreza 619 |2024-10-24 00:00:00|2024-10-25 00:00:00|\n",
      "|eef5227c-fadf-46e1-a8f1-be969e48965d|1          |Macejkovic, Walter and Cummings |TrailRunner Impreza 619 |2024-10-29 00:00:00|2024-10-30 00:00:00|\n",
      "+------------------------------------+-----------+--------------------------------+------------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "# of records in Delta table None\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import col\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/order-count-daily\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    # Convert total_sale_price to a standard numeric format\n",
    "    #df = df.withColumn(\"total_sale_pice\", col(\"total_sale_pice\").cast(\"decimal(20, 8)\"))\n",
    "\n",
    "    print(f\"# of records in Delta table {df.show(truncate=False)}\")\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3591ac-d170-4678-941a-0fc8f0e21f2b",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85865700-d09c-49f2-bab7-4547edcce6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_6.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pathlib import Path\n",
    "from pyspark.sql.functions import max \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\"\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Using an existing Spark session; only runtime SQL configurations will take effect.\")\n",
    "\n",
    "conf = SparkConf().setAppName('Low Inventory Alert Count')\\\n",
    "        .set(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\")\\\n",
    "        .set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "        .set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    "        .set(\"log4j.logger.org.apache.hadoop.util.NativeCodeLoader\", \"ERROR\")\\\n",
    "        .set(\"log4j.logger.org.apache.spark.internal.config.native-code-path\", \"ERROR\")\n",
    "\n",
    "#builder = spark.builder.appName(\"MyApp\") \\\n",
    "#    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "#    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "#spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "delta_table_path = \"/opt/spark/delta-tables/order-count-daily\"\n",
    "\n",
    "# Read data from the Delta table\n",
    "#df = spark.read.format(\"delta\").load(\"/opt/spark/delta-tables/low_stock_alert\")\n",
    "#print(f\"# of Low Stock alerts: {df.count()}\")\n",
    "\n",
    "if Path(delta_table_path, \"_delta_log\").exists():\n",
    "    df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    \n",
    "    latest_df_pd = df.toPandas()\n",
    "    \n",
    "    # Convert time columns to datetime format\n",
    "    #latest_df_pd['starttime'] = pd.to_datetime(latest_df_pd['starttime'])\n",
    "    #latest_df_pd['endtime'] = pd.to_datetime(latest_df_pd['endtime'])\n",
    "    latest_df_pd['upd_name']= latest_df_pd['name']+\"(\"+latest_df_pd['brand']+\")\"\n",
    "   \n",
    "    # Create the grouped bar chart\n",
    "    fig = px.bar(\n",
    "        latest_df_pd,\n",
    "        x=\"upd_name\",\n",
    "        y=\"order_count\",\n",
    "        color=\"starttime\",\n",
    "        barmode=\"group\",\n",
    "        title=\"Product Orders by Date\",\n",
    "        labels={\"upd_name\": \"Product Name\", \"order_count\": \"Order Count\", \"starttime\": \"Date\"}\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No Data available currently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ab748-fa72-409b-9c2d-e25420d73bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
